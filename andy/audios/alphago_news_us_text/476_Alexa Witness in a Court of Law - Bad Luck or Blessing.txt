in a trial what's worse no witness or a robotic one that can get it wrong
in 1999 Lawrence lessig publish a book titled code and other laws of cyberspace warranty readers about the potential of software going as far as the nine people's rights granted by law nearly two decades later mr. lessig has moved on but his predictions still ring true maybe you've heard of automated takedown request for YouTube videos where all my forms censoring messages because they happen to detect a swear word inside a longer one and shirt those affected can always appeal to a human at administrator but it's a lengthy process and it doesn't stop the machine from censoring Around the Clock until recently such incidents were seen as relatively harmless after all it's just entertainment right but it seemed that magazine were marked by now we live surrounded by devices such as voice assistant GPS receivers and even computerized pacemakers together they tracked are every word position and heartbeat
and everything they recorded can now be used in a court of law like last March when James Bates a murder suspect was confronted with audio capture by his Amazon Echo the night of the crime did it count as self-incrimination the legal issues are best left a professional but even if such evidence is used responsibly how reliable is it we've all heard of car navigation systems indicating a road where there wasn't any or of driverless cars advancing without noticing the passerby walking in front a person's testimony is accepted in court if it's likely to be true based on the experience knowledge training and appearance of honesty of the witness now imagine there was no human witness how do you determine the credibility of the device
this question is cute especially because we trust our devices Decades of Science Fiction have taught us to get movies all computers are always precise exact and most importantly accurate in reality they're programmed by human who can and do make mistakes so the date of the suffers using can be incorrect out of context or incomplete so you get the wrong ad so that's no big deal but what happens when the AI makes a mistake and a person ends up in court when people got injured in car collisions no one band card is that somebody invented the seat belt so what can the seat belt for the helmet be in this case it's important to remember people must prove themselves reliable before they're allowed to make an important decision even then they can still slip-up treat machines the same way understanding us offers decision-making process is also important
before building a bridge and engineered Ross blueprint then experts double-check though we were talking about software the blueprints are the source code and all too often. The code is kept a secret by the companies that own it even when it's a matter of public safety for instance in medical devices were taking for granted Diagnostics made by software code which is not public so if they're not working within the company experts can't make sure that the diagnostic is correct or understand how it was achieved what's more nowadays there programs capable of improving them self with little to no human supervision such programs should still be able to let us know how they came to a decision Angelina the AI game designer is built that way we she can explain herself her Creator cancel peek behind the seat but alphago is a black box hard to decipher even by its own makers
which of the two would you entrust to make an important decision for you think about that till then just smile and wave boys smile and wave