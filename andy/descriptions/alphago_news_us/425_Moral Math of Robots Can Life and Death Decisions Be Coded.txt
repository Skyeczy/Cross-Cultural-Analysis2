A self-driving car has a split second to decide whether to turn into oncoming traffic or hit a child who has lost control of her bicycle. An autonomous drone needs to decide whether to risk the lives of busload of civilians or lose a long-sought terrorist. How does a machine make an ethical decision? Can it “learn” to choose in situations that would strain human decision making? Can morality be programmed? We will tackle these questions and more as the leading AI experts, roboticists, neuroscientists, and legal experts debate the ethics and morality of thinking machines.Subscribe to our YouTube Channel for all the latest from WSF.Visit our Website: http://www.worldsciencefestival.com/Like us on Facebook: https://www.facebook.com/worldscience...Follow us on twitter: https://twitter.com/WorldSciFestOriginal Program Date: June 4, 2016MODERATOR: Bill BlakemorePARTICIPANTS: Fernando Diaz, Colonel Linell Letendre, Gary Marcus, Matthias Scheutz, Wendell WallachCan Life and Death Decisions Be Coded? 00:06Siri... What is the meaning of life? 1:49Participant introductions 4:01Asimov's Three Laws of Robotics 6:22In 1966 ELIZA was one of the first artificial intelligence systems. 10:20What is ALPHAGO? 15:43 TAY Tweets the first AI twitter bot. 19:25Can you test learning Systems? 26:31Robots and automatic reasoning demonstration 30:31 How do driverless cars work? 39:32What is the trolley problem? 49:00What is autonomy in military terms? 56:40Are landmines the first automated weapon? 1:10:30Defining how artificial intelligence learns 1:16:03Using Minecraft to teach AI about humans and their interactions  1:22:27Should we be afraid that AI will take over the world? 1:25:08