dear fellow Scholars this is two minute papers with Carriage when I say here in earlier episodes when it came to learning techniques we almost always talk about supervised learning this means that we give the address I'm about to of images and some additional information for instance that these images the pig dogs or cats than the learning algorithm is exposed to know images that have never seen before and test to be able to classify them correctly it is kind of like a teacher sitting next to a student providing supervision then the exam comes with new questions this is supervised learning and as you have seen from more than 180 episodes of too many papers there's no doubt that this is an enormously successful field of research however this means that we have to label our data sets so we have to add some additional information to every image we have this is very laborious task which is typically performed by researchers or
show crowdsourcing both of which takes a lot of funding and hundreds of work hours but if you think about it we have a ton of videos on the internet you always hear these mind-melting new statistics on how many hours of video footage is uploaded to YouTube every day of course we could hire all the employees in the world to annotate these videos frame by frame to tell the algorithm that this is a guitar this is an accordion or a keyboard and we would still not be able to learn on most of what's upload it but it would be so great to have an algorithm that can learn on unlabeled data however there are learning techniques in the field of unsupervised learning which means that the algorithm is given a bunch of images or any media and is instructed to learn on it without any additional information there's no teacher to supervise the learning by itself and then this work the objective is to learn both Visual and audio related tasks in an answer provide
matter so for instance if we look at this layer of the visual subnetwork will find euron's that gets very excited when they see for instance someone playing an accordion and each of the neuron causing this layer belong to different object classes I surely have something like this for papers and here comes the car it goes crazy part 1 this technique not only classifies the frame of the videos but it also creates semantic heat maps with chores which part of the image is responsible for the sounds that we hear this is insanity to accomplish this their Vision subnetwork on the video part and the separate audio sub Network to learn about the sounds and at the last step all this information is fused together to obtain Carly goes crazy part 2 this makes the network able to guess what are the audio and the video stream correspond to each other it looks at a man with a fiddle listens to a sound clip and we'll see
what are the two correspond to each other wow the Audience Network also learn the concept of human voices the sound of water wind music live concert and much much more and the answer is yes it is remarkably close to human level performance on sound classification and all this is provided by the two networks that were train from scratch and no supervision is required we don't need to annotate these videos nailed it and please don't get this wrong it's not like deep mind has suddenly invented unsupervised learning not at all this is a field that has been actively researched for decades it's just that we rarely see really Punchy results like these ones here truly incredible work if you enjoy this episode and you feel that eight of these videos a month is worth a dollar please consider supporting us on patreon details are available in the video description